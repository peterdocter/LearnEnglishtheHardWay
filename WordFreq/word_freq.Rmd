---
title: "用 R 语言统计英文书词频"
output: html_document
---

加载包

```{r,collapse=TRUE,comment='#>'}
library(dplyr)
library(readr)
```

导入词汇表。
```{r,collapse=TRUE,comment='#>'}
df = read_csv('~/Documents/WordFreq/COCA_top5000.csv') 
df1 = select(df, Word) # 选择 word 这一列

df2 = read_csv('~/Documents/WordFreq/Metadata/MathLinearBookFreq.csv')
df2
```

采用 dplyr 里的anti_join 函数把 df2 里面不匹配 df1 前 1000 的单词挑出来，大白话就是把你不怎么认识的词挑出来
```{r,collapse=TRUE,comment='#>'}
df3 = anti_join(df2, df1[0:1000,], by = 'Word') %>%
  arrange(desc(Frequency))
df3
summary(df3)
```

但还有个问题，数学书里面有太两位数的符号，属于无效单词，也可删除
```{r,collapse=TRUE,comment='#>'}
df4 <- filter(df3, nchar(Word) > 2)
summary(df4)
df4
```

大功告成，写入文件，即可
```{r,collapse=TRUE,comment='#>'}
write_csv(df4, '~/Documents/WordFreq/LA_MIT_freeq.csv')
```
